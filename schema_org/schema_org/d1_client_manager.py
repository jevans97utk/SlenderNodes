"""
_______________________________________________________________________________

d1_client_manager.py puts all the code managing GMN through API
calls and the DataONE python library into one place. It was written
as part of an OAI-PMH based adapter, but can be incorporated into
any adapter implementation.

Last tested on dataone.libclient version 2.4.0
_______________________________________________________________________________

"""

import io
import sys

# D1.
import d1_common.const
import d1_client.mnclient_2_0
import d1_common.checksum

DATETIME_FORMAT = '%Y-%m-%dT%H:%M:%SZ'


class D1ClientManager:
    # Initialize the client manager with an instance of a member node client
    def __init__(self, gmn_baseurl, auth_cert, auth_cert_key, logger):
        """
        Parameters
        ----------
        gmn_baseurl:
            The base URL configured for the Generic Member Node installation.
        auth_cert:
            Certificate used for authenticating with the GMN server
            to make changes. If the adapter script is being run in
            standalone mode during development, then this might be a
            certificate generated by the GMN server's local CA which
            was setup during installation of GMN. However, if this GMN
            instance has been registered with a DataONE Coordinating Node
            environment, then the certificate provided by DataONE should
            be used for authenticating with GMN.  :param auth_cert_key:
            Also used for authentication. Similarly to the certificate
            described above, either a locally generated certificate key
            or a DataONE provided key will be used, depending on whether
            this node is still in development or is registered.
        """
        if auth_cert is None and auth_cert_key is None:
            verify_tls = False
        else:
            verify_tls = True

        timeout = 120.0
        self.client = d1_client.mnclient_2_0.MemberNodeClient_2_0(
            gmn_baseurl,
            cert_pem_path=auth_cert,
            cert_key_path=auth_cert_key,
            timeout=timeout,
            verify_tls=verify_tls
        )
        self.logger = logger

    def get_last_harvest_time(self):
        """
        A function which checks the member node to see the most
        recently modified/created date of any object in GMN.  Assumes
        GMN is returning listobjects response in order of oldest to
        newest. This datetime can then be used as the opening timeslice
        for harvesting new data.

        Returns
        -------
            Returns either the datesysmetadatamodified property date
            of the most recent object in GMN, or returns an arbitrary
            start time to capture everything if no data in GMN yet.
        """
        try:
            objcount = self.client.listObjects(start=0, count=0).total
            if objcount > 0:
                obj = self.client.listObjects(start=objcount - 1, count=1)
                return obj.objectInfo[0].dateSysMetadataModified.strftime(DATETIME_FORMAT)  # noqa : E501
            else:
                # if 0 objects are returned, then this is the first ever
                # harvester run so grab EVERYTHING.
                return '1900-01-01T00:00:00Z'
        except Exception as e:
            self.logger.error(e)
            msg = (
                "Failed to get last harvested time.  "
                "Exiting program prematurely."
            )
            self.logger.error(msg)
            sys.exit(1)

    def check_if_identifier_exists(self, native_identifier_sid):
        """
        The main adapter script uses this function to determine if a
        science metadata record retrieved in a prior harvest already
        exists in GMN.

        Parameters
        ------
        native_identifier_sid:
            The native repository's system identifier for a record
            harvested in a query, which is implemented as the DataONE
            seriesId.

        Returns
        -------
            True if found or False if not (or a failed message if the
            check didn't work for some reason).
        """
        msg = f"Checking for existance of {native_identifier_sid}"
        self.logger.info(msg)

        checkExistsDict = {}
        try:
            sys_meta = self.client.getSystemMetadata(native_identifier_sid)
        except d1_common.types.exceptions.NotFound:
            checkExistsDict['outcome'] = 'no'
        except Exception as e:
            self.logger.error(e)
            checkExistsDict['outcome'] = 'failed'
        else:
            checkExistsDict = dict(
                outcome='yes',
                record_date=sys_meta.dateUploaded,
                current_version_id=sys_meta.identifier.value()
            )
        finally:
            return checkExistsDict

    def load_science_metadata(self, *, sci_metadata_bytes=None,
                              native_identifier_sid=None,
                              record_date=None, system_metadata=None):
        """
        Loads a new science metadata record into GMN using the .create() method
        from the Member Node API.

        Parameters
        ----------
        sci_metadata_bytes:
            The bytes of the science metadata record as utf-encoded string.
        native_identifier_sid:
            The unique identifier of the metadata record in the native
            repository.
        record_date:
            The datestamp parsed from the OAI-PMH record. This becomes
            the dateUploaded in GMN.

        Returns
        -------
            True if the object successfully created or False if not. This
            allows the main program to track the number of successfully
            created objects.
        """
        msg = (
            f"Loading science metadata for SID {native_identifier_sid} "
            f"with identifier/PID/checksum "
            f"{system_metadata.identifier.value()}."
        )
        self.logger.info(msg)

        try:
            self.client.create(system_metadata.identifier.value(),
                               io.BytesIO(sci_metadata_bytes),
                               system_metadata)
        except Exception as e:
            msg = 'Failed to create object with SID: ' + native_identifier_sid
            self.logger.error(msg)
            self.logger.error(e)
            return False
        else:
            msg = (
                f'CREATED object with SID: {native_identifier_sid} / '
                f'PID: {system_metadata.identifier.value()}.'
            )
            self.logger.info(msg)
            return True

    def update_science_metadata(self, *, sci_metadata_bytes=None,
                                native_identifier_sid=None, record_date=None,
                                old_version_pid=None, system_metadata=None):
        """
        When a record is harvested from an OAI-PMH query whose
        native repository identifier already exists as a seriesId
        in GMN, then it is understood that the record has been
        modified in the native repository. The .update() API method
        is called to obsolete the old version of the science metadata
        in GMN, and load the changed record as a new object. The
        .update() method automates setting the obsoletes / obsoleted
        by properties of both old and new objects in order to encode
        the relationship between the two, so there is no need to
        explicitly assign them.

        Parameters
        ----------
        sci_metadata_bytes:
            The bytes of the new version of the science metadata record
            as a utf-encoded string.
        native_identifier_sid:
            The identifier of the record in its native repository which
            is implemented as the seriesId property in GMN.
        record_date:
            The datestamp parsed from the OAI-PMH record. This becomes
            the dateUploaded in GMN. If the dateUploaded of the most
            current version of the record in GMN is the same as the
            datestamp of the record from the OAI-PMH harvest, then the
            record hasn't really been modified.  If the datestamp from the
            harvest IS different, this means something about the record
            as changed and it should be processed as an update in GMN.
            The evaluation of whether or not a record has changed is
            done in the main adapter program when it calls
            .check_if_identifier_exists() from d1_client_manager.
        old_version_pid:
            The pid for the existing version of the pid that about to
            be updated.

        Returns
        -------
            True if the object successfully updated or False if not. This
            allows the main program to track the number of updated
            objects in a given run.
        """
        msg = (
            f"Updating/obsoleting science metadata for existing PID "
            f"{old_version_pid} and replacing with "
            f"{system_metadata.identifier.value()}."
        )
        self.logger.info(msg)

        try:
            self.client.update(old_version_pid,
                               io.BytesIO(sci_metadata_bytes),
                               system_metadata.identifier.value(),
                               system_metadata)
        except Exception as e:
            self.logger.error(e)
            return False
        else:
            return True

    def archive_science_metadata(self, current_version_pid):
        """
        This function is called by the main adapter script to archive
        an existing object in GMN.When GMN is first populated,
        records which already have deleted status in the native
        repository will not be harvested from the repository into
        GMN. By contrast, once a record has already been created
        into GMN, if it later becomes deleted, then the record will
        be archived in GMN.

        Parameters
        ----------
        current_version_pid:
            The GMN unique identifier (pid) of the science metadata
            record to be archived.

        Returns
        -------
        True if the object successfully archived or False if not. This
        allows the main program to track the number of archived objects
        in a given run.
        """

        try:
            self.client.archive(current_version_pid)
        except Exception as e:
            msg = 'Failed to ARCHIVE object PID: ' + current_version_pid
            self.logger.error(msg)
            self.logger.error(e)
            return False
        else:
            return True
